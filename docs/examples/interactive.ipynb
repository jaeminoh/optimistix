{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5879c173-a927-452e-917f-e76066ec1aee",
   "metadata": {},
   "source": [
    "# Interactively step through a solve\n",
    "\n",
    "Sometimes you might want to perform an optimisation just one step at a time (or a few steps at a time), and perhaps do some other computations in between. A common example is when training a neural network, and looking to continually monitor performance of the model on a validation set.\n",
    "\n",
    "One option is to repeatedly call e.g. `optx.minimise(..., throw=False, max_steps=1)`. However if that seems inelegant/inefficient to you, then it is possible to use the solvers yourself directly.\n",
    "\n",
    "Let's look at an example where we run an [`optimistix.Bisection`][] search, and output the interval considered at each step.\n",
    "\n",
    "!!! info\n",
    "\n",
    "    This is a relatively advanced API surface. In particular, no default arguments are provided, and all functions are assumed to return `aux`iliary information (which as in this example may be just `None`). See [`optimistix.AbstractRootFinder`][] for details on each of the arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95fe84f3-420c-45c2-90ab-bd5495725adc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating point 0.0 with value -0.7615941762924194.\n",
      "Evaluating point 0.5 with value -0.4051482081413269.\n",
      "Evaluating point 0.75 with value -0.19137555360794067.\n",
      "Evaluating point 0.875 with value -0.07904523611068726.\n",
      "Evaluating point 0.9375 with value -0.021835267543792725.\n",
      "Evaluating point 0.96875 with value 0.006998121738433838.\n",
      "Evaluating point 0.953125 with value -0.007436692714691162.\n",
      "Evaluating point 0.9609375 with value -0.0002237558364868164.\n",
      "Evaluating point 0.96484375 with value 0.0033860206604003906.\n",
      "Evaluating point 0.962890625 with value 0.0015808343887329102.\n",
      "Evaluating point 0.9619140625 with value 0.0006784796714782715.\n",
      "Found solution 0.96142578125 with value 0.00022733211517333984.\n"
     ]
    }
   ],
   "source": [
    "import equinox as eqx  # https://github.com/patrick-kidger/equinox\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import optimistix as optx\n",
    "\n",
    "\n",
    "# Seek `y` such that `y - tanh(y + 1) = 0`.\n",
    "@eqx.filter_jit\n",
    "def fn(y, args):\n",
    "    out = y - jnp.tanh(y + 1)\n",
    "    aux = None\n",
    "    return out, aux\n",
    "\n",
    "\n",
    "solver = optx.Bisection(rtol=1e-3, atol=1e-3)\n",
    "# The initial guess for the solution\n",
    "y = jnp.array(0.0)\n",
    "# Any auxiliary information to pass to `fn`.\n",
    "args = None\n",
    "# The interval to search over. Required for `optx.Bisection`.\n",
    "options = dict(lower=-1, upper=1)\n",
    "# The shape+dtype of the output of `fn`\n",
    "f_struct = jax.ShapeDtypeStruct((), jnp.float32)\n",
    "aux_struct = None\n",
    "# Any Lineax tags describing the structure of the Jacobian matrix d(fn)/dy.\n",
    "# (In this case it's just a 1x1 matrix, so these don't matter.)\n",
    "tags = frozenset()\n",
    "\n",
    "\n",
    "def solve(y, solver):\n",
    "    # These arguments are always fixed throughout interactive solves.\n",
    "    step = eqx.filter_jit(\n",
    "        eqx.Partial(solver.step, fn=fn, args=args, options=options, tags=tags)\n",
    "    )\n",
    "    terminate = eqx.filter_jit(\n",
    "        eqx.Partial(solver.terminate, fn=fn, args=args, options=options, tags=tags)\n",
    "    )\n",
    "\n",
    "    # Initial state before we start solving.\n",
    "    state = solver.init(fn, y, args, options, f_struct, aux_struct, tags)\n",
    "    done, result = terminate(y=y, state=state)\n",
    "\n",
    "    # Alright, enough setup. Let's do the solve!\n",
    "    while not done:\n",
    "        print(f\"Evaluating point {y} with value {fn(y, args)[0]}.\")\n",
    "        y, state, aux = step(y=y, state=state)\n",
    "        done, result = terminate(y=y, state=state)\n",
    "    if result != optx.RESULTS.successful:\n",
    "        print(f\"Oh no! Got error {result}.\")\n",
    "    y, _, _ = solver.postprocess(fn, y, aux, args, options, state, tags, result)\n",
    "    print(f\"Found solution {y} with value {fn(y, args)[0]}.\")\n",
    "\n",
    "\n",
    "solve(y, solver)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f291fb5-f99c-4c21-8615-480a02536031",
   "metadata": {},
   "source": [
    "This example also highlights a detail of how many solvers work: whilst they keep searching for a better solution, they don't necessarily keep a copy of the best-so-far value around. Keeping this copy around would require extra memory, after all.\n",
    "\n",
    "In this case, notice how one of the earlier points got a loss of `-0.000223755836486816`, which is actually slightly smaller than the loss from the final solution. (The returned solution is only guaranteed to be something satisfying the tolerance conditions.)\n",
    "\n",
    "If we want to be sure of having the best-so-far value, then we can make a copy of it by using [`optimistix.BestSoFarRootFinder`][]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6eecac4-e32c-4989-b9d0-6316a8fb7eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating point 0.0 with value -0.7615941762924194.\n",
      "Evaluating point 0.5 with value -0.4051482081413269.\n",
      "Evaluating point 0.75 with value -0.19137555360794067.\n",
      "Evaluating point 0.875 with value -0.07904523611068726.\n",
      "Evaluating point 0.9375 with value -0.021835267543792725.\n",
      "Evaluating point 0.96875 with value 0.006998121738433838.\n",
      "Evaluating point 0.953125 with value -0.007436692714691162.\n",
      "Evaluating point 0.9609375 with value -0.0002237558364868164.\n",
      "Evaluating point 0.96484375 with value 0.0033860206604003906.\n",
      "Evaluating point 0.962890625 with value 0.0015808343887329102.\n",
      "Evaluating point 0.9619140625 with value 0.0006784796714782715.\n",
      "Found solution 0.9609375 with value -0.0002237558364868164.\n"
     ]
    }
   ],
   "source": [
    "best_so_far_solver = optx.BestSoFarRootFinder(solver)\n",
    "solve(y, best_so_far_solver)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
